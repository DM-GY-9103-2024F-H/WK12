{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week I\n",
    "\n",
    "More Neural Networks for images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://github.com/DM-GY-9103-2024F-H/9103-utils/raw/main/src/data_utils.py\n",
    "!wget -q https://github.com/DM-GY-9103-2024F-H/9103-utils/raw/main/src/image_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import nn\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "from data_utils import classification_error, display_confusion_matrix\n",
    "from image_utils import make_image\n",
    "\n",
    "from WKI_utils import LFWUtils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review\n",
    "\n",
    "Let's quickly review the model from last week.\n",
    "\n",
    "### Load Data\n",
    "\n",
    "The version of `LFWUtils.train_test_split()` in this week's utils class has an optional parameter `return_loader` that will return the data already in sensible `DataLoader` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = LFWUtils.train_test_split(0.3, return_loader=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at Data\n",
    "\n",
    "Our `DataLoaders` are iterable objects, which means we need to do a bit of unpacking to get to actual labels and pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = next(iter(train))\n",
    "print(LFWUtils.LABELS[label[0]])\n",
    "display(make_image(img[0], width=130))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model, Optimizer, Cost/Loss Function\n",
    "\n",
    "This is the model from last week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_length = LFWUtils.IMAGE_SIZE[0] * LFWUtils.IMAGE_SIZE[1]\n",
    "\n",
    "model = nn.Sequential(\n",
    "  nn.Dropout(0.2),\n",
    "  nn.Linear(image_length, image_length // 8),\n",
    "  nn.ReLU(),\n",
    "\n",
    "  nn.Dropout(0.2),\n",
    "  nn.Linear(image_length // 8, len(LFWUtils.LABELS)),\n",
    ")\n",
    "\n",
    "learning_rate = 1e-5\n",
    "optim = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(32):\n",
    "  model.train()\n",
    "  for x, y in train:\n",
    "    optim.zero_grad()\n",
    "    y_pred = model(x)\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "  if e % 4 == 0:\n",
    "    print(f\"Epoch: {e} loss: {loss.item():.4f}\")\n",
    "\n",
    "print(f\"Epoch: {e} loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval\n",
    "\n",
    "Could've been in the loop, but we already know this model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels, train_predictions = LFWUtils.get_labels(model, train)\n",
    "test_labels, test_predictions = LFWUtils.get_labels(model, test)\n",
    "train_error = classification_error(train_labels, train_predictions)\n",
    "test_error = classification_error(test_labels, test_predictions)\n",
    "print(f\"train error: {train_error:.4f}, test error: {test_error:.4f}\")\n",
    "\n",
    "display_confusion_matrix(train_labels, train_predictions, display_labels=LFWUtils.LABELS)\n",
    "display_confusion_matrix(test_labels, test_predictions, display_labels=LFWUtils.LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Training Harder Again\n",
    "\n",
    "### Image augmentation\n",
    "\n",
    "# ADD IMAGE:\n",
    "\n",
    "https://pytorch.org/vision/0.13/auto_examples/plot_transforms.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = next(iter(train))\n",
    "print(LFWUtils.LABELS[label[0]])\n",
    "display(make_image(img[0], width=130))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original (130 x 170)\n",
    "transforms = v2.Compose([\n",
    "    v2.RandomHorizontalFlip(p=0.5),\n",
    "    v2.RandomRotation(degrees=15),\n",
    "    v2.RandomPerspective(distortion_scale=0.25, p=0.5),\n",
    "    # v2.RandomResizedCrop(size=(170, 130), scale=(.75, .9), antialias=True),\n",
    "    # v2.RandomAffine(degrees=15, translate=(0.1, 0.3), scale=(1.1, 1.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timg = transforms(make_image(img[0], width=130))\n",
    "display(timg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = LFWUtils.train_test_split(0.3, return_loader=True, train_transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = next(iter(train))\n",
    "print(LFWUtils.LABELS[label[0]])\n",
    "display(make_image(img[0], width=130))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_length = LFWUtils.IMAGE_SIZE[0] * LFWUtils.IMAGE_SIZE[1]\n",
    "\n",
    "model = nn.Sequential(\n",
    "  nn.Dropout(0.2),\n",
    "  nn.Linear(image_length, image_length // 8),\n",
    "  nn.ReLU(),\n",
    "\n",
    "  nn.Dropout(0.2),\n",
    "  nn.Linear(image_length // 8, len(LFWUtils.LABELS)),\n",
    ")\n",
    "\n",
    "learning_rate = 1e-5\n",
    "optim = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(32):\n",
    "  model.train()\n",
    "  for x, y in train:\n",
    "    optim.zero_grad()\n",
    "    y_pred = model(x)\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "  if e % 4 == 0:\n",
    "    print(f\"Epoch: {e} loss: {loss.item():.4f}\")\n",
    "\n",
    "print(f\"Epoch: {e} loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels, train_predictions = LFWUtils.get_labels(model, train)\n",
    "test_labels, test_predictions = LFWUtils.get_labels(model, test)\n",
    "train_error = classification_error(train_labels, train_predictions)\n",
    "test_error = classification_error(test_labels, test_predictions)\n",
    "print(f\"train error: {train_error:.4f}, test error: {test_error:.4f}\")\n",
    "\n",
    "display_confusion_matrix(train_labels, train_predictions, display_labels=LFWUtils.LABELS)\n",
    "display_confusion_matrix(test_labels, test_predictions, display_labels=LFWUtils.LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost vs Eval\n",
    "\n",
    "Cost can go down without changing accuracy.\n",
    "\n",
    "`true_labels = [0, 1]`\n",
    "\n",
    "`prediction_probs := [0.1, 0.9], [0.9, 0.1]` $\\Rightarrow$\n",
    "`prediction_labels = [1, 0]`\n",
    "\n",
    "accuracy: $0$, loss: $1.7$\n",
    "\n",
    "`prediction_probs := [0.45, 0.55], [0.51, 0.49]` $\\Rightarrow$\n",
    "`prediction_labels = [1, 0]`\n",
    "\n",
    "accuracy: $0$, loss: $0.7$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nl = nn.CrossEntropyLoss()\n",
    "\n",
    "l = torch.Tensor([0, 1]).long()\n",
    "p0 = torch.Tensor([[0.1, 0.9], [0.9, 0.1]])\n",
    "p1 = torch.Tensor([[0.45, 0.55], [0.51, 0.49]])\n",
    "\n",
    "nl(p0, l), nl(p1, l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutions\n",
    "\n",
    "# IMAGE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import nn\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "from data_utils import classification_error, display_confusion_matrix\n",
    "from image_utils import make_image\n",
    "\n",
    "from WKI_utils import LFWUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original (130 x 170)\n",
    "transforms = v2.Compose([\n",
    "\tv2.RandomHorizontalFlip(p=0.5),\n",
    "\tv2.RandomRotation(degrees=15),\n",
    "\tv2.RandomPerspective(distortion_scale=0.25, p=0.5),\n",
    "\t# v2.RandomResizedCrop(size=(170, 130), scale=(.75, .9), antialias=True),\n",
    "\t# v2.RandomAffine(degrees=15, translate=(0.1, 0.3), scale=(1.1, 1.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = LFWUtils.train_test_split(0.3, cnn_loader=True, train_transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = next(iter(train))\n",
    "display(v2.ToPILImage()(img[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width, height = LFWUtils.IMAGE_SIZE\n",
    "linear_length = (((width//2)-1)) * (((height//2)-1)) * 32\n",
    "\n",
    "model = nn.Sequential(\n",
    "  nn.Dropout(0.2),\n",
    "  nn.Conv2d(1, 32, 3),\n",
    "  nn.ReLU(),\n",
    "  nn.MaxPool2d(2, 2),\n",
    "\n",
    "  # More Convs ?\n",
    "\n",
    "  nn.Flatten(1, -1),\n",
    "\n",
    "  nn.Linear(linear_length, 512),\n",
    "  nn.ReLU(),\n",
    "\n",
    "  nn.Linear(512, len(LFWUtils.LABELS)),\n",
    ")\n",
    "\n",
    "learning_rate = 2e-2\n",
    "optim = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(32):\n",
    "  model.train()\n",
    "  for x, y in train:\n",
    "    optim.zero_grad()\n",
    "    y_pred = model(x)\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "  if e % 4 == 0:\n",
    "    print(f\"Epoch: {e} loss: {loss.item():.4f}\")\n",
    "\n",
    "print(f\"Epoch: {e} loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels, train_predictions = LFWUtils.get_labels(model, train)\n",
    "test_labels, test_predictions = LFWUtils.get_labels(model, test)\n",
    "train_error = classification_error(train_labels, train_predictions)\n",
    "test_error = classification_error(test_labels, test_predictions)\n",
    "print(f\"train error: {train_error:.4f}, test error: {test_error:.4f}\")\n",
    "\n",
    "display_confusion_matrix(train_labels, train_predictions, display_labels=LFWUtils.LABELS)\n",
    "display_confusion_matrix(test_labels, test_predictions, display_labels=LFWUtils.LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNNs\n",
    "\n",
    "## Object Detection\n",
    "\n",
    "- Regression + Classification\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gradio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
